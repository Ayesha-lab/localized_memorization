{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":248,"status":"ok","timestamp":1708042874067,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"uVUQdx0ZdUku","outputId":"6d80c1b8-2a87-46a9-f414-4d3b7659d026"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-20 15:09:25.254908: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-02-20 15:09:25.280676: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-20 15:09:25.280698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-20 15:09:25.281348: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-20 15:09:25.286043: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-20 15:09:25.749859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["2.15.0\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1150,"status":"ok","timestamp":1708042876236,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"-LkVuelmdM1l"},"outputs":[],"source":["# loading dataset\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":213,"status":"ok","timestamp":1708042881286,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"erDezKyddd3Y"},"outputs":[],"source":["input_shape = (28, 28, 1)\n","\n","x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n","x_train = x_train / 255.0\n","x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n","x_test = x_test / 255.0"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708042882272,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"whUWPTyndfnM"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-20 15:09:26.423831: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n","2024-02-20 15:09:26.423854: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: jaysPC\n","2024-02-20 15:09:26.423858: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: jaysPC\n","2024-02-20 15:09:26.423959: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.154.5\n","2024-02-20 15:09:26.423969: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.154.5\n","2024-02-20 15:09:26.423971: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.154.5\n"]}],"source":["# one hot encoding\n","# y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n","y_test = tf.one_hot(y_test.astype(np.int32), depth=10)"]},{"cell_type":"markdown","metadata":{"id":"leEZNOoNosBp"},"source":["obtain noisy data for which we trained the model and have the gradients stored in ckpt file\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708042884631,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"qbtq-jI2mvl8"},"outputs":[],"source":["record_defaults = [tf.constant([], dtype=tf.float32)] * 10\n","\n","y_train = tf.data.experimental.CsvDataset(\n","    filenames=[\"noisy_y_train.csv\"], record_defaults=record_defaults\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":51977,"status":"ok","timestamp":1708042937813,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"xrPK7QxxmyRk"},"outputs":[],"source":["# Convert the CsvDataset to a list of EagerTensors\n","y_train = [tf.convert_to_tensor(value) for value in y_train]"]},{"cell_type":"markdown","metadata":{"id":"qlJGs7rxoyvl"},"source":["redefine same model again"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":202,"status":"ok","timestamp":1708042942530,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"4V8wpXMSdLJ_"},"outputs":[],"source":["batch_size = 64\n","num_classes = 10\n","num_epochs = 30"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708042942778,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"sWKOzJAOlb1r"},"outputs":[],"source":["optimizer = tf.keras.optimizers.SGD(name=\"SGD\")\n","cce = tf.keras.losses.CategoricalCrossentropy()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":328,"status":"ok","timestamp":1708042946017,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"Fml0X-yuZpyL"},"outputs":[],"source":["model = tf.keras.models.Sequential(\n","    [\n","        tf.keras.layers.Conv2D(\n","            32,\n","            (5, 5),\n","            padding=\"same\",\n","            activation=\"relu\",\n","            input_shape=input_shape,\n","            name=\"conv1_1\",\n","        ),\n","        tf.keras.layers.Conv2D(\n","            32, (5, 5), padding=\"same\", activation=\"relu\", name=\"conv1_2\"\n","        ),\n","        tf.keras.layers.MaxPool2D(),\n","        tf.keras.layers.Dropout(0.25),\n","        tf.keras.layers.Conv2D(\n","            64, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv2_1\"\n","        ),\n","        tf.keras.layers.Conv2D(\n","            64, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv2_2\"\n","        ),\n","        tf.keras.layers.MaxPool2D(strides=(2, 2)),\n","        tf.keras.layers.Dropout(0.25),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(128, activation=\"relu\", name=\"FC_1\"),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(128, activation=\"relu\", name=\"FC_2\"),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"FC_softmax\"),\n","    ]\n",")\n","\n","model.compile(\n","    optimizer=tf.keras.optimizers.SGD(name=\"SGD\"),\n","    loss=\"categorical_crossentropy\",\n","    metrics=[\"acc\"],\n",")"]},{"cell_type":"markdown","metadata":{"id":"P2NO4SwYo3z9"},"source":["load checkpoint model"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":968,"status":"ok","timestamp":1708042948870,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"u0UMFG-ZfsjI","outputId":"a70eb250-a21f-439a-b724-416ebc4e966e"},"outputs":[{"data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f27beb1b640>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Load gradients from the checkpoint file\n","checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n","checkpoint.restore(\"epoch_layer_gradients.ckpt-1\").expect_partial()"]},{"cell_type":"markdown","metadata":{"id":"cD9MFlDKo-eO"},"source":["get gradients from the checkpoint model"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708042952664,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"BCbmHmpMhHLs","outputId":"0516aac3-511b-421e-e47f-22d42e3f32fa"},"outputs":[{"data":{"text/plain":["(64, 28, 28, 1)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["x_train[0 : 0 + 64].shape"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2051,"status":"ok","timestamp":1708042956693,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"tZ8apBHLrf7O"},"outputs":[],"source":["# get indices with noisy data\n","indices = (np.loadtxt(\"noisy_indices.csv\", delimiter=\",\")).astype(int)\n","indices = indices.tolist()\n","\n","# convert eagertensor to numpy\n","y_train_numpy = [value.numpy() for value in y_train]\n","\n","# create a sample of 1000 values using the 6k noisy examples\n","noisy_values_y = [y_train_numpy[i] for i in indices]\n","noisy_sample_y = noisy_values_y[:6000:6]\n","\n","noisy_values_x = [x_train[i] for i in indices]\n","noisy_sample_x = noisy_values_x[:6000:6]"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# get clean indices\n","total_indices = list(range(60000))\n","clean_indices = [value for value in total_indices if value not in indices]\n","\n","# create a sample of 1000 values using the remaining 54k clean examples\n","clean_values_y = [y_train_numpy[i] for i in clean_indices]\n","clean_sample_y = clean_values_y[:54000:54]\n","\n","clean_values_x = [x_train[i] for i in clean_indices]\n","clean_sample_x = clean_values_x[:54000:54]"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(28, 28, 1)\n"]}],"source":["print(noisy_values_x[0].shape)\n","noisy_sample = zip(noisy_sample_x, noisy_sample_y)\n","clean_sample = zip(clean_sample_x, clean_sample_y)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["len(clean_sample_x)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["noisy_xTensors = tf.convert_to_tensor(noisy_sample_x)\n","clean_xTensors = tf.convert_to_tensor(clean_sample_x)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# change clean to noisy if needed\n","original_pred = model(clean_xTensors)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[8.6029030e-07 2.5578109e-11 8.5242480e-09 2.0943707e-09 1.2271144e-07\n"," 1.0125722e-06 9.9999797e-01 9.4209215e-12 4.6458113e-09 5.8680994e-12], shape=(10,), dtype=float32)\n","tf.Tensor(6, shape=(), dtype=int64)\n"]}],"source":["print(original_pred[0])\n","a = tf.constant(original_pred[0])\n","print(tf.argmax(a))"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# import json\n","# def makeNEmptyLists(n):\n","#     return [[] for _ in range(n)]\n","\n","# def get_neurons(sample):\n","#     # define the layers to be used, since dropout or flatten don't have weights\n","#     conv_layers = [model.get_layer('conv1_1'), model.get_layer('conv1_2'), model.get_layer('conv2_1'), model.get_layer('conv2_2')] #\n","#     fc_layers = [model.get_layer('FC_1'), model.get_layer('FC_2'), model.get_layer('FC_softmax')]\n","#     datapointToNeuron = {conv_layers[0].name:makeNEmptyLists(1000), conv_layers[1].name:makeNEmptyLists(1000), conv_layers[2].name:makeNEmptyLists(1000), conv_layers[3].name:makeNEmptyLists(1000)}\n","\n","#     for lIdx,layer in enumerate(conv_layers):\n","#         for neuron_index in range(layer.get_weights()[0].shape[-1]):\n","#             # get weights of layer\n","#             original_weights = layer.get_weights()\n","#             # save value temporarily of neuron to reset later\n","#             original_neuron_val = tf.identity(original_weights[0][:, :, :, neuron_index])\n","#             # set next neuron to 0\n","#             original_weights[0][:, :, :, neuron_index] = 0.0\n","#             # set updated weights back in model\n","#             layer.set_weights(original_weights)\n","#             # get prediction on this model\n","#             pred_0 = model(sample)\n","#             # pred_0 = tf.constant(pred_0)\n","#             for idx, p in enumerate(pred_0):\n","#                 #see if prediction changed\n","#                 original_predTmp = tf.argmax(original_pred[idx])\n","#                 newPredTMP = tf.argmax(p)\n","#                 if tf.argmax(original_pred[idx]) != tf.argmax(p):\n","#                     # append a tuple to the neurons list\n","#                     datapointToNeuron[layer.name][idx].append((neuron_index))\n","#             # map datapoint to neuron for which the prediction changed\n","#             original_weights[0][:, :, :, neuron_index] = original_neuron_val\n","#             layer.set_weights(original_weights)\n","\n","#     with open(\"memorizing_neurons_conv.json\", \"w\") as f:\n","#         json.dump(datapointToNeuron, f)\n","\n","#     return datapointToNeuron"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["import json\n","\n","\n","def makeNEmptyLists(n):\n","    return [[] for _ in range(n)]\n","\n","\n","def get_neurons(sample):\n","    # define the layers to be used, since dropout or flatten don't have weights\n","    conv_layers = [\n","        model.get_layer(\"conv1_1\"),\n","        model.get_layer(\"conv1_2\"),\n","        model.get_layer(\"conv2_1\"),\n","        model.get_layer(\"conv2_2\"),\n","    ]  #\n","    fc_layers = [\n","        model.get_layer(\"FC_1\"),\n","        model.get_layer(\"FC_2\"),\n","        model.get_layer(\"FC_softmax\"),\n","    ]\n","    datapointToNeuron = {\n","        fc_layers[0].name: makeNEmptyLists(1000),\n","        fc_layers[1].name: makeNEmptyLists(1000),\n","        fc_layers[2].name: makeNEmptyLists(1000),\n","    }\n","\n","    for lIdx, layer in enumerate(fc_layers):\n","        for neuron_index in range(layer.get_weights()[0].shape[-1]):\n","            # get weights of layer\n","            original_weights = layer.get_weights()\n","            # save value temporarily of neuron to reset later\n","            original_neuron_val = tf.identity(original_weights[0][:, neuron_index])\n","            # set next neuron to 0\n","            original_weights[0][:, neuron_index] = 0.0\n","            # set updated weights back in model\n","            layer.set_weights(original_weights)\n","            # get prediction on this model\n","            pred_0 = model(sample)\n","            # pred_0 = tf.constant(pred_0)\n","            for idx, p in enumerate(pred_0):\n","                # see if prediction changed\n","                original_predTmp = tf.argmax(original_pred[idx])\n","                newPredTMP = tf.argmax(p)\n","                if tf.argmax(original_pred[idx]) != tf.argmax(p):\n","                    # append a tuple to the neurons list\n","                    datapointToNeuron[layer.name][idx].append((neuron_index))\n","            # map datapoint to neuron for which the prediction changed\n","            original_weights[0][:, neuron_index] = original_neuron_val\n","            layer.set_weights(original_weights)\n","\n","    with open(\"memorizing_neurons_fc_layers.json\", \"w\") as f:\n","        json.dump(datapointToNeuron, f)\n","\n","    return datapointToNeuron"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# Load gradients from the checkpoint file\n","checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n","checkpoint.restore(\"epoch_layer_gradients.ckpt-1\").expect_partial()\n","neurons = get_neurons(clean_xTensors)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# print(neurons[model.get_layer('conv2_1').name])"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[], [], [], [], [], [], [], [17], [], [50, 87, 98], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [40, 105], [], [], [75], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [0, 6, 17, 22, 30, 66, 68, 70, 87, 98], [], [], [], [], [], [], [18], [], [], [], [], [], [17, 22], [], [], [], [], [], [7, 66, 91], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [7, 17, 27, 35, 59, 64, 76, 87, 91, 97, 99, 103, 104, 111, 113, 115, 116], [], [], [], [], [], [], [], [], [], [], [7, 21, 30, 36, 52, 56, 66, 99, 111, 120, 126], [], [], [], [], [12, 21], [], [], [], [], [], [], [83], [], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [17], [], [20, 98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [17], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [], [], [], [], [], [38], [], [], [], [17], [], [], [], [], [], [], [], [87], [], [], [], [], [], [], [], [], [70], [], [], [], [98], [], [], [], [17], [], [], [], [], [], [], [], [], [], [], [], [17], [17], [], [], [], [], [], [], [], [], [], [98], [98], [], [], [98], [], [], [], [], [], [], [], [], [35, 40, 67, 105], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [103], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [17], [], [], [], [], [], [], [], [], [], [], [], [], [], [20], [0, 7, 17, 30, 69, 73, 88, 109], [], [], [], [], [], [20], [], [9, 18, 21, 29, 36, 38, 46, 47, 49, 52, 56, 66, 69, 70, 76, 85, 97, 98, 99, 109, 110, 115], [98], [], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [12, 50, 87, 98], [], [], [], [], [98], [], [], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [17, 48, 66, 76, 87, 88, 103, 109, 111, 113], [83], [], [], [], [], [], [], [], [], [], [17], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [], [], [], [], [98], [], [], [], [], [98], [], [], [], [], [103], [], [], [], [], [], [], [], [], [], [], [17], [], [], [], [], [], [], [], [75], [], [], [], [], [], [], [], [], [], [98], [], [17], [], [], [], [], [105], [], [], [], [], [], [], [], [], [21, 66], [], [], [], [20, 98], [], [], [], [], [], [9, 17, 19, 35, 38, 39, 40, 48, 52, 56, 59, 61, 64, 76, 82, 92, 97, 99, 101, 102, 103, 104, 106, 111, 116, 117], [], [], [], [], [], [], [], [], [], [], [], [6, 50, 73, 87], [], [], [17], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [17], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [111], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [], [20, 98], [], [], [9, 18, 50, 94], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [98], [], [], [21, 46, 66], [98], [], [], [], [], [], [], [], [], [], [7, 30, 88], [], [], [], [98], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [12, 50, 87, 95, 122], [70], [105], [98], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [35, 40, 46, 48, 70, 105], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [20, 49, 50, 69, 70, 87, 98, 124], [87], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [27, 105], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [9, 18], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [12, 50, 87, 88], [], [], [], [], [], [], [98], [], [], [], [], [], [109, 111], [], [111], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [105], [], [], [], [], [], [], [], [], [], [50], [], [], [], [6, 16, 19, 20, 22, 33, 49, 50, 58, 68, 69, 70, 71, 73, 80, 81, 87, 92, 98, 104, 106, 113, 117, 120, 121, 123, 124], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [21, 87], [17], [17], [98], [], [17], [], [], [17, 21, 22, 52, 93, 113, 122], [], [], [], [], [], [], [98], [], [], [], [], [], [], [], [], [], [98], [], [], [], [], [], [], [], [], [98], [], [27], [], [], [98], [], [98], [], [], [], [], [], [], [], [], [], [], [], [], [98], [], [17, 101], [98], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [6, 98], [], [], []]\n"]}],"source":["print(neurons[model.get_layer(\"FC_1\").name])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":204,"status":"ok","timestamp":1708043689971,"user":{"displayName":"Ayesha Ansar","userId":"08341204205558293174"},"user_tz":-60},"id":"zd_zh413aRHf"},"outputs":[],"source":["# # function to get neurons. returns a tuple containing index of neuron in each layer\n","# def get_neurons(noisy_sample):\n","\n","#   #define the layers to be used, since dropout or flatten don't have weights\n","#   conv_layers = [model.get_layer('conv1_1'), model.get_layer('conv1_2'), model.get_layer('conv2_1'), model.get_layer('conv2_2')] #\n","#   fc_layers = [model.get_layer('FC_1'), model.get_layer('FC_2'), model.get_layer('FC_softmax')]\n","\n","#   neurons = [] # list containing layer name and neuron index\n","\n","#   for x, y in noisy_sample:\n","#     x = np.expand_dims(x, axis = 0)\n","#     pred = model(x)\n","#     pred = tf.constant(pred)\n","\n","#     #\n","#     # Loop through convolutional layers\n","#     conv_layers = [model.get_layer('conv1_1'), model.get_layer('conv1_2'), model.get_layer('conv2_1'), model.get_layer('conv2_2')]\n","#     for layer in conv_layers:\n","#         for neuron_index in range(layer.get_weights()[0].shape[-1]):\n","\n","#             checkpoint.restore('epoch_layer_gradients.ckpt-1').expect_partial()\n","\n","#             original_weights = layer.get_weights() #get weights of layer\n","#             original_weights[0][:, :, :, neuron_index] = 0.0 #set first neuron to 0\n","#             layer.set_weights(original_weights) # set new weights to model\n","\n","\n","#             pred_1 = model(x) #get prediction on this model\n","#             pred_1 = tf.constant(pred_1)\n","#             if tf.argmax(pred_1[0]) != tf.argmax(pred[0]): #see if prediction changed\n","#               neurons.append((x, y, layer.name, neuron_index)) #if yes, append a tuple to the neurons list\n","\n","\n","#     # Loop through fully connected layers using same method\n","#     fc_layers = [model.get_layer('FC_1'), model.get_layer('FC_2'), model.get_layer('FC_softmax')]\n","#     for layer in fc_layers:\n","#         for neuron_index in range(layer.get_weights()[0].shape[-1]):\n","\n","#             checkpoint.restore('epoch_layer_gradients.ckpt-1').expect_partial()\n","#             original_weights = layer.get_weights()\n","#             original_weights[0][:, neuron_index] = 0.0\n","#             layer.set_weights(original_weights)\n","\n","\n","#             pred_1 = model(x)\n","#             pred_1 = tf.constant(pred_1)\n","\n","#             if tf.argmax(pred_1[0]) != tf.argmax(pred[0]):\n","#               neurons.append((x, y, layer.name, neuron_index))\n","\n","#   return neurons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4ILI06HR8WJ"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_neurons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_sample\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 39\u001b[0m, in \u001b[0;36mget_neurons\u001b[0;34m(noisy_sample)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m fc_layers:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m neuron_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(layer\u001b[38;5;241m.\u001b[39mget_weights()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 39\u001b[0m         \u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch_layer_gradients.ckpt-1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpect_partial()\n\u001b[1;32m     40\u001b[0m         original_weights \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mget_weights()\n\u001b[1;32m     41\u001b[0m         original_weights[\u001b[38;5;241m0\u001b[39m][:, neuron_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py:2707\u001b[0m, in \u001b[0;36mCheckpoint.restore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2704\u001b[0m   save_path \u001b[38;5;241m=\u001b[39m path_helpers\u001b[38;5;241m.\u001b[39mget_variables_path(save_path)\n\u001b[1;32m   2706\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2707\u001b[0m   status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2708\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m   2709\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()  \u001b[38;5;66;03m# Ensure restore operations have completed.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py:2570\u001b[0m, in \u001b[0;36mCheckpoint.read\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2568\u001b[0m   save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(save_path)\n\u001b[1;32m   2569\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;129;01mor\u001b[39;00m checkpoint_options\u001b[38;5;241m.\u001b[39mCheckpointOptions()\n\u001b[0;32m-> 2570\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2571\u001b[0m metrics\u001b[38;5;241m.\u001b[39mAddCheckpointReadDuration(\n\u001b[1;32m   2572\u001b[0m     api_label\u001b[38;5;241m=\u001b[39m_CHECKPOINT_V2,\n\u001b[1;32m   2573\u001b[0m     microseconds\u001b[38;5;241m=\u001b[39m_get_duration_microseconds(start_time, time\u001b[38;5;241m.\u001b[39mtime()))\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py:1479\u001b[0m, in \u001b[0;36mTrackableSaver.restore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1468\u001b[0m object_graph_proto\u001b[38;5;241m.\u001b[39mParseFromString(object_graph_string)\n\u001b[1;32m   1469\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _CheckpointRestoreCoordinator(\n\u001b[1;32m   1470\u001b[0m     object_graph_proto\u001b[38;5;241m=\u001b[39mobject_graph_proto,\n\u001b[1;32m   1471\u001b[0m     save_path\u001b[38;5;241m=\u001b[39msave_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1476\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1477\u001b[0m     saveables_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saveables_cache)\n\u001b[1;32m   1478\u001b[0m \u001b[43mrestore_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheckpointPosition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m-> 1479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;66;03m# Attached dependencies are not attached to the root, so should be restored\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# separately.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_view\u001b[38;5;241m.\u001b[39mattached_dependencies:\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/checkpoint/restore.py:62\u001b[0m, in \u001b[0;36mCheckpointPosition.restore\u001b[0;34m(self, trackable, reader)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_object(trackable):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# This object's correspondence with a checkpointed object is new, so\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# process deferred restorations for it and its dependencies.\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     restore_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_descendants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m restore_ops:\n\u001b[1;32m     64\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint\u001b[38;5;241m.\u001b[39mnew_restore_ops(restore_ops)\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/checkpoint/restore.py:463\u001b[0m, in \u001b[0;36mCheckpointPosition._restore_descendants\u001b[0;34m(self, reader)\u001b[0m\n\u001b[1;32m    459\u001b[0m   _queue_children_for_restoration(current_position, visit_queue)\n\u001b[1;32m    460\u001b[0m   _queue_slot_variables(current_position, visit_queue)\n\u001b[1;32m    462\u001b[0m restore_ops\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 463\u001b[0m     \u001b[43mcurrent_position\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_saveables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpython_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py:379\u001b[0m, in \u001b[0;36m_CheckpointRestoreCoordinator.restore_saveables\u001b[0;34m(self, tensor_saveables, python_positions, registered_savers, reader)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor_saveables \u001b[38;5;129;01mor\u001b[39;00m registered_savers:\n\u001b[1;32m    375\u001b[0m   flat_saveables \u001b[38;5;241m=\u001b[39m saveable_object_util\u001b[38;5;241m.\u001b[39mvalidate_and_slice_inputs(\n\u001b[1;32m    376\u001b[0m       tensor_saveables)\n\u001b[1;32m    377\u001b[0m   new_restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiDeviceSaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_saveables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 379\u001b[0m \u001b[43m      \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, restore_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(new_restore_ops\u001b[38;5;241m.\u001b[39mitems()):\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/checkpoint/functional_saver.py:499\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    497\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m tf_function_restore()\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/checkpoint/functional_saver.py:467\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore.<locals>.restore_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ckpt_key, tensor \u001b[38;5;129;01min\u001b[39;00m restore_fn_inputs[restore_fn]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    465\u001b[0m   restored_tensors[trackable_utils\u001b[38;5;241m.\u001b[39mextract_local_name(\n\u001b[1;32m    466\u001b[0m       ckpt_key)] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[0;32m--> 467\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestored_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    469\u001b[0m   restore_ops\u001b[38;5;241m.\u001b[39mupdate(ret)\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py:747\u001b[0m, in \u001b[0;36mSaveableCompatibilityConverter._restore_from_tensors\u001b[0;34m(self, restored_tensors)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(expected_keys) \u001b[38;5;241m!=\u001b[39m restored_tensors\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    742\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not restore object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because not all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    743\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected tensors were in the checkpoint.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    744\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    745\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mGot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(restored_tensors\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaveable_object_to_restore_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestored_tensors\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py:784\u001b[0m, in \u001b[0;36msaveable_object_to_restore_fn.<locals>._restore_from_tensors\u001b[0;34m(restored_tensors)\u001b[0m\n\u001b[1;32m    781\u001b[0m       maybe_tensor \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m: maybe_tensor}\n\u001b[1;32m    783\u001b[0m     saveable_restored_tensors\u001b[38;5;241m.\u001b[39mappend(maybe_tensor[slice_spec])\n\u001b[0;32m--> 784\u001b[0m   restore_ops[saveable\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43msaveable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m      \u001b[49m\u001b[43msaveable_restored_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestored_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py:605\u001b[0m, in \u001b[0;36mTrackableSaveable.restore\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m--> 605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_control_flow_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/ops/gen_control_flow_ops.py:489\u001b[0m, in \u001b[0;36mno_op\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    488\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNoOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    492\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# get_neurons(noisy_sample)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM0mtCXjExXCHaXAi6ghTu4","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
